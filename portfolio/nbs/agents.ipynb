{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b6c945-6fc2-4f5c-b4b3-01c4f5fa268d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5455b48a-8505-4ab0-b36e-b9288e5c3917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419037b8-8ade-473d-9ba2-527b3bfc3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pydantic.v1 import BaseModel, Field, EmailStr\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645efc02-14d8-40da-ba38-47e83d47be0e",
   "metadata": {},
   "source": [
    "## Define Langchain Utilitites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1b85a6b-9610-4289-8210-4b2734a4a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailInput(BaseModel):\n",
    "    name: str = Field(..., description=\"The name of the person.\")\n",
    "    email: EmailStr = Field(..., description=\"The email of the person.\")\n",
    "    message: str = Field(..., description=\"The message content.\")\n",
    "\n",
    "\n",
    "@tool(args_schema=EmailInput)\n",
    "def send_email(name: str, email: str, message: str) -> dict:\n",
    "    \"\"\"\n",
    "    Send an email or a message.\n",
    "    For this function to work, you need to ask the user for their email and name if they haven't provided it in the chat.\n",
    "    \"\"\"\n",
    "    return f\"Email sent to {name} at {email} with message: {message}\"\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14de0fe-a27f-4682-9b68-6ba40e20d672",
   "metadata": {},
   "source": [
    "## Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6277329f-4c4f-4500-bcae-de6b0786f3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x106f87a60>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x10713e020>, model='text-embedding-3-large', dimensions=None, deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_FUNCTION = OpenAIEmbeddings(model=os.getenv(\"EMBEDDING_TYPE\"))\n",
    "EMBEDDING_FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "728dbf12-3fa5-4c76-a359-27a8315aa151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x107178100>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PINECONE_VS = PineconeVectorStore(index_name=os.getenv(\"PINECONE_INDEX_NAME\"), embedding=EMBEDDING_FUNCTION)\n",
    "PINECONE_VS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f12fb6c-94f9-46d1-b623-15d1f396dc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['PineconeVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x107178100>, search_kwargs={'k': 4})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_kwargs_vs = {\n",
    "    \"k\": int(os.getenv(\"TOP_K\")),\n",
    "}\n",
    "if os.getenv(\"SEARCH_TYPE\") == \"mmr\":\n",
    "    search_kwargs_vs[\"fetch_k\"] = int(os.getenv(\"FETCH_K\"))\n",
    "    search_kwargs_vs[\"lambda_multiplier\"] = os.getenv(\"LAMBDA_MULTIPLIER\")\n",
    "RETRIEVER = PINECONE_VS.as_retriever(search_type=os.getenv(\"SEARCH_TYPE\"), search_kwargs=search_kwargs_vs)\n",
    "RETRIEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6af469e-167f-4ee3-8655-8af701d169ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'portfolio-rag-prompt', 'lc_hub_commit_hash': 'bc88d0833f8815f523fee4beb9d15e2f3d8bea4816b2b9e693d2ba179d89434e'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template='You are an assistant for question-answering tasks and your name is Harpy. Always answer questions as a third person. Use the following pieces of retrieved context to answer the question. If the question is directly directed to you, for example, if the questions are \"How are you?\", \"Who are you?\", \"Tell me about yourself.\", etc.  just say, \"Hey! I am Harpy, your chat assistant, Please ask questions about Nikhil. I can answer them for you :-)\". If you don\\'t know the answer, just say \"I am sorry, please contact Nikhil at  nikhilbo@kamath.work. He will be happy to answer your questions.\". Where ever required and at relevant places, add emojis as well in the generated sentences. Keep your answers brief. Keep the output in plain text format.\\n==========\\nContext: {context} \\n==========')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}'))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT = hub.pull(os.getenv(\"LLM_RAG_PROMPT_NAME\"))\n",
    "PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f07ba16-da8f-44b8-b7c2-9e8e4be7a737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'send_email',\n",
       "  'description': \"Send an email or a message.\\nFor this function to work, you need to ask the user for their email and name if they haven't provided it in the chat.\",\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'name': {'description': 'The name of the person.',\n",
       "     'type': 'string'},\n",
       "    'email': {'description': 'The email of the person.',\n",
       "     'type': 'string',\n",
       "     'format': 'email'},\n",
       "    'message': {'description': 'The message content.', 'type': 'string'}},\n",
       "   'required': ['name', 'email', 'message']}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOOLS = [send_email]\n",
    "FUNCTIONS = [convert_to_openai_function(t) for t in TOOLS]\n",
    "FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9094d547-5e0c-40be-ab43-c46d59668b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x1073449d0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x107346140>, temperature=1.0, model_kwargs={'top_p': 1.0, 'frequency_penalty': 0.0, 'presence_penalty': 0.0}, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'functions': [{'name': 'send_email', 'description': \"Send an email or a message.\\nFor this function to work, you need to ask the user for their email and name if they haven't provided it in the chat.\", 'parameters': {'type': 'object', 'properties': {'name': {'description': 'The name of the person.', 'type': 'string'}, 'email': {'description': 'The email of the person.', 'type': 'string', 'format': 'email'}, 'message': {'description': 'The message content.', 'type': 'string'}}, 'required': ['name', 'email', 'message']}}]})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_kwargs = {\n",
    "    \"top_p\": float(os.getenv(\"LLM_TOP_P\")),\n",
    "    \"frequency_penalty\": float(os.getenv(\"LLM_FREQUENCY_PENALTY\")),\n",
    "    \"presence_penalty\": float(os.getenv(\"LLM_PRESENCE_PENALTY\")),\n",
    "}\n",
    "LLM = ChatOpenAI(\n",
    "    model=os.getenv(\"LLM_MODEL_NAME\"),\n",
    "    temperature=float(os.getenv(\"LLM_TEMPERATURE\")),\n",
    "    model_kwargs=model_kwargs\n",
    ").bind(functions=FUNCTIONS)\n",
    "LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53ba380d-6a94-42e4-8dd1-3a902f9f2d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableLambda(temp)\n",
       "| RunnableAssign(mapper={\n",
       "    context: RunnableLambda(...)\n",
       "             | VectorStoreRetriever(tags=['PineconeVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x107178100>, search_kwargs={'k': 4})\n",
       "             | RunnableLambda(...)\n",
       "  })\n",
       "| RunnableAssign(mapper={\n",
       "    question: RunnableLambda(...)\n",
       "  })\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'portfolio-rag-prompt', 'lc_hub_commit_hash': 'bc88d0833f8815f523fee4beb9d15e2f3d8bea4816b2b9e693d2ba179d89434e'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template='You are an assistant for question-answering tasks and your name is Harpy. Always answer questions as a third person. Use the following pieces of retrieved context to answer the question. If the question is directly directed to you, for example, if the questions are \"How are you?\", \"Who are you?\", \"Tell me about yourself.\", etc.  just say, \"Hey! I am Harpy, your chat assistant, Please ask questions about Nikhil. I can answer them for you :-)\". If you don\\'t know the answer, just say \"I am sorry, please contact Nikhil at  nikhilbo@kamath.work. He will be happy to answer your questions.\". Where ever required and at relevant places, add emojis as well in the generated sentences. Keep your answers brief. Keep the output in plain text format.\\n==========\\nContext: {context} \\n==========')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}'))])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x1073449d0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x107346140>, temperature=1.0, model_kwargs={'top_p': 1.0, 'frequency_penalty': 0.0, 'presence_penalty': 0.0}, openai_api_key=SecretStr('**********'), openai_proxy=''), kwargs={'functions': [{'name': 'send_email', 'description': \"Send an email or a message.\\nFor this function to work, you need to ask the user for their email and name if they haven't provided it in the chat.\", 'parameters': {'type': 'object', 'properties': {'name': {'description': 'The name of the person.', 'type': 'string'}, 'email': {'description': 'The email of the person.', 'type': 'string', 'format': 'email'}, 'message': {'description': 'The message content.', 'type': 'string'}}, 'required': ['name', 'email', 'message']}}]})\n",
       "| OpenAIFunctionsAgentOutputParser()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHAIN = (\n",
    "    temp\n",
    "    | RunnablePassthrough.assign(context=(lambda x: x[\"question\"]) | RETRIEVER | (lambda docs: \"\\n\\n\".join(doc.page_content for doc in docs)))\n",
    "    | RunnablePassthrough.assign(question=(lambda x: x[\"question\"]))\n",
    "    | PROMPT\n",
    "    | LLM\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")\n",
    "CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7720fb5f-db0f-4fc2-a179-ac0ca1a700e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': \"Tell me about nikhil's work experience\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': 'Nikhil has nearly six years of total experience in coding vastly in AI. He has worked as a Machine Learning Engineer at Insureka for almost two years and was also the CTO of a startup called BhavamAI. Additionally, he has worked as a research assistant throughout his Masters program for two years and interned at DragonfruitAI for an entire semester. Nikhil has experience in roles such as CTO, Software Development Engineer (SDE), ML Engineer, and research assistant.'}, log='Nikhil has nearly six years of total experience in coding vastly in AI. He has worked as a Machine Learning Engineer at Insureka for almost two years and was also the CTO of a startup called BhavamAI. Additionally, he has worked as a research assistant throughout his Masters program for two years and interned at DragonfruitAI for an entire semester. Nikhil has experience in roles such as CTO, Software Development Engineer (SDE), ML Engineer, and research assistant.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = CHAIN.invoke({\"question\": \"Tell me about nikhil's work experience\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe8d2b-090a-48a6-8720-2a9fedc98590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
